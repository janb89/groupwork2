{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "# <u> Flight delay forecasting </u>\n",
    "### Machine Learning Project by:\n",
    "Tamara Pallien & Frederic Baumeister\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"res/title.jpg\" height=450>\n",
    "\n",
    "\n",
    " Photo by D. C. Cavalleri: https://www.pexels.com/de-de/foto/flughafen-2421196/\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1200 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# necessary imports \n",
    "\n",
    "\"\"\" Data Manipulation and Visualization\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import seaborn as sns\n",
    "#import plotly.express as px\n",
    "\n",
    "\n",
    "\"\"\" Machine Learning \"\"\"\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\"\"\" Time \"\"\"\n",
    "from datetime import datetime, timedelta\n",
    "from time import sleep \n",
    "\n",
    "\"\"\" External APIs\"\"\"\n",
    "import airportsdata\n",
    "from meteostat import Point, Daily\n",
    "\n",
    "\n",
    "\"\"\" PyScripts \"\"\"\n",
    "#import Flight_routes\n",
    "#import Airport_efficiency\n",
    "\n",
    "\"\"\"Global Values\"\"\"\n",
    "RSEED = 42\n",
    "figure(figsize=(10, 10), dpi=120)\n",
    "airports = airportsdata.load('IATA')\n",
    "\n",
    "\n",
    "\"\"\"other\"\"\"\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Series' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/fredericbaumeister/neuefische/groupwork2/EDA.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/fredericbaumeister/neuefische/groupwork2/EDA.ipynb#ch0000003?line=3'>4</a>\u001b[0m test_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39mdata/Test.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/fredericbaumeister/neuefische/groupwork2/EDA.ipynb#ch0000003?line=5'>6</a>\u001b[0m df\u001b[39m.\u001b[39mhead()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/fredericbaumeister/neuefische/groupwork2/EDA.ipynb#ch0000003?line=7'>8</a>\u001b[0m df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39;49mdtypes(\u001b[39m'\u001b[39;49m\u001b[39mfloat64\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/fredericbaumeister/neuefische/groupwork2/EDA.ipynb#ch0000003?line=9'>10</a>\u001b[0m df\u001b[39m.\u001b[39mhead()\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Series' object is not callable"
     ]
    }
   ],
   "source": [
    "\"\"\" Read dataset\"\"\"\n",
    "\n",
    "df = pd.read_csv('data/Train.csv')\n",
    "test_df = pd.read_csv('data/Test.csv')\n",
    "\n",
    "df.head()\n",
    "\n",
    "df = df.dtypes('float64')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depart Coordinates\n",
      "SXF missing in Airportsdata: 332 rows affected\n",
      "Arrival Coordinates\n",
      "SXF missing in Airportsdata: 332 rows affected\n"
     ]
    }
   ],
   "source": [
    "# Reading Airport API Data\n",
    "\n",
    "\"\"\"To Avoid long wait times due to limits within the APIs, the API responses for the Training Data are saved in .csv files \"\"\"\n",
    "\n",
    "arr = df.DEPSTN.unique()\n",
    "err_arr = []\n",
    "port_dict = {}\n",
    "for el in arr:\n",
    "    try:\n",
    "        port_dict[el] = tuple([airports[el].get(k) for k in ['lat', 'lon']])\n",
    "    except KeyError:\n",
    "        err_arr.append(el)\n",
    "\n",
    "df['Dep_coor'] = df['DEPSTN'].map(port_dict)\n",
    "\n",
    "print('Depart Coordinates')\n",
    "for err in err_arr: \n",
    "    print(f'{err} missing in Airportsdata: {df.DEPSTN.value_counts()[err]} rows affected')\n",
    "\n",
    "arr = df.ARRSTN.unique()\n",
    "err_arr = []\n",
    "port_dict = {}\n",
    "for el in arr:\n",
    "    try:\n",
    "        port_dict[el] =tuple([airports[el].get(k) for k in ['lat', 'lon']])\n",
    "    except KeyError:\n",
    "        err_arr.append(el)\n",
    "\n",
    "df['Arr_coor'] = df['ARRSTN'].map(port_dict)\n",
    "\n",
    "print('Arrival Coordinates')\n",
    "for err in err_arr: \n",
    "    print(f'{err} missing in Airportsdata: {df.ARRSTN.value_counts()[err]} rows affected')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidURL",
     "evalue": "URL can't contain control characters. \"/v2/daily/(<meteostat.interface.point.Point object at 0x15c6bbeb0>, Timestamp('2018-01-01 00:00:00'), Timestamp('2018-12-31 00:00:00')).csv.gz\" (found at least ' ')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidURL\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/fredericbaumeister/neuefische/groupwork2/EDA.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/fredericbaumeister/neuefische/groupwork2/EDA.ipynb#ch0000005?line=10'>11</a>\u001b[0m start \u001b[39m=\u001b[39m datetime(\u001b[39m2018\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/fredericbaumeister/neuefische/groupwork2/EDA.ipynb#ch0000005?line=11'>12</a>\u001b[0m end \u001b[39m=\u001b[39m datetime(\u001b[39m2018\u001b[39m, \u001b[39m12\u001b[39m, \u001b[39m31\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/fredericbaumeister/neuefische/groupwork2/EDA.ipynb#ch0000005?line=12'>13</a>\u001b[0m data \u001b[39m=\u001b[39m Daily((coor, start, end))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/fredericbaumeister/neuefische/groupwork2/EDA.ipynb#ch0000005?line=13'>14</a>\u001b[0m data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mfetch()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/fredericbaumeister/neuefische/groupwork2/EDA.ipynb#ch0000005?line=14'>15</a>\u001b[0m port_dict[record[\u001b[39m0\u001b[39m]] \u001b[39m=\u001b[39m data\n",
      "File \u001b[0;32m~/neuefische/groupwork2/.venv/lib/python3.9/site-packages/meteostat/interface/daily.py:98\u001b[0m, in \u001b[0;36mDaily.__init__\u001b[0;34m(self, loc, start, end, model, flags)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m     89\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     90\u001b[0m     loc: Union[pd\u001b[39m.\u001b[39mDataFrame, Point, \u001b[39mlist\u001b[39m, \u001b[39mstr\u001b[39m],  \u001b[39m# Station(s) or geo point\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     96\u001b[0m \n\u001b[1;32m     97\u001b[0m     \u001b[39m# Initialize time series\u001b[39;00m\n\u001b[0;32m---> 98\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init_time_series(loc, start, end, model, flags)\n",
      "File \u001b[0;32m~/neuefische/groupwork2/.venv/lib/python3.9/site-packages/meteostat/interface/timeseries.py:170\u001b[0m, in \u001b[0;36mTimeSeries._init_time_series\u001b[0;34m(self, loc, start, end, model, flags)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flags \u001b[39m=\u001b[39m flags\n\u001b[1;32m    169\u001b[0m \u001b[39m# Get data for all weather stations\u001b[39;00m\n\u001b[0;32m--> 170\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[1;32m    172\u001b[0m \u001b[39m# Load source flags through map file\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[39m# if flags are explicitly requested or\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[39m# model data is excluded\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[39mif\u001b[39;00m flags \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m model:\n",
      "File \u001b[0;32m~/neuefische/groupwork2/.venv/lib/python3.9/site-packages/meteostat/interface/meteodata.py:127\u001b[0m, in \u001b[0;36mMeteoData._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    124\u001b[0m     datasets \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_datasets()\n\u001b[1;32m    126\u001b[0m     \u001b[39m# Data Processings\u001b[39;00m\n\u001b[0;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m processing_handler(\n\u001b[1;32m    128\u001b[0m         datasets, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load_data, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprocesses, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mthreads\n\u001b[1;32m    129\u001b[0m     )\n\u001b[1;32m    131\u001b[0m \u001b[39m# Empty DataFrame\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[39mreturn\u001b[39;00m pd\u001b[39m.\u001b[39mDataFrame(columns\u001b[39m=\u001b[39m[\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_types])\n",
      "File \u001b[0;32m~/neuefische/groupwork2/.venv/lib/python3.9/site-packages/meteostat/core/loader.py:59\u001b[0m, in \u001b[0;36mprocessing_handler\u001b[0;34m(datasets, load, cores, threads)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39m# Single-thread processing\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m     \u001b[39mfor\u001b[39;00m dataset \u001b[39min\u001b[39;00m datasets:\n\u001b[0;32m---> 59\u001b[0m         output\u001b[39m.\u001b[39mappend(load(\u001b[39m*\u001b[39;49mdataset))\n\u001b[1;32m     61\u001b[0m \u001b[39m# Remove empty DataFrames\u001b[39;00m\n\u001b[1;32m     62\u001b[0m filtered \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mfilter\u001b[39m(\u001b[39mlambda\u001b[39;00m df: df\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39msize \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m, output))\n",
      "File \u001b[0;32m~/neuefische/groupwork2/.venv/lib/python3.9/site-packages/meteostat/interface/meteodata.py:59\u001b[0m, in \u001b[0;36mMeteoData._load_data\u001b[0;34m(self, station, year)\u001b[0m\n\u001b[1;32m     54\u001b[0m     df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_pickle(path)\n\u001b[1;32m     56\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     57\u001b[0m \n\u001b[1;32m     58\u001b[0m     \u001b[39m# Get data from Meteostat\u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m     df \u001b[39m=\u001b[39m load_handler(\n\u001b[1;32m     60\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mendpoint, file, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_columns, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_types, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parse_dates\n\u001b[1;32m     61\u001b[0m     )\n\u001b[1;32m     63\u001b[0m     \u001b[39m# Validate and prepare data for further processing\u001b[39;00m\n\u001b[1;32m     64\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgranularity \u001b[39m==\u001b[39m Granularity\u001b[39m.\u001b[39mNORMALS \u001b[39mand\u001b[39;00m df\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39msize \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     65\u001b[0m         \u001b[39m# Add weather station ID\u001b[39;00m\n\u001b[1;32m     66\u001b[0m         \u001b[39m# pylint: disable=unsupported-assignment-operation\u001b[39;00m\n",
      "File \u001b[0;32m~/neuefische/groupwork2/.venv/lib/python3.9/site-packages/meteostat/core/loader.py:82\u001b[0m, in \u001b[0;36mload_handler\u001b[0;34m(endpoint, path, columns, types, parse_dates, coerce_dates)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[39mLoad a single CSV file into a DataFrame\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     80\u001b[0m \n\u001b[1;32m     81\u001b[0m     \u001b[39m# Read CSV file from Meteostat endpoint\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m     df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\n\u001b[1;32m     83\u001b[0m         endpoint \u001b[39m+\u001b[39;49m path,\n\u001b[1;32m     84\u001b[0m         compression\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgzip\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     85\u001b[0m         names\u001b[39m=\u001b[39;49mcolumns,\n\u001b[1;32m     86\u001b[0m         dtype\u001b[39m=\u001b[39;49mtypes,\n\u001b[1;32m     87\u001b[0m         parse_dates\u001b[39m=\u001b[39;49mparse_dates,\n\u001b[1;32m     88\u001b[0m     )\n\u001b[1;32m     90\u001b[0m     \u001b[39m# Force datetime conversion\u001b[39;00m\n\u001b[1;32m     91\u001b[0m     \u001b[39mif\u001b[39;00m coerce_dates:\n",
      "File \u001b[0;32m~/neuefische/groupwork2/.venv/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/neuefische/groupwork2/.venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/neuefische/groupwork2/.venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    577\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/neuefische/groupwork2/.venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:934\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    933\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 934\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/neuefische/groupwork2/.venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1218\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1214\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1215\u001b[0m \u001b[39m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m \u001b[39m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1217\u001b[0m \u001b[39m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1218\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(  \u001b[39m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1219\u001b[0m     f,\n\u001b[1;32m   1220\u001b[0m     mode,\n\u001b[1;32m   1221\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1222\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1223\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1224\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1225\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1226\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1227\u001b[0m )\n\u001b[1;32m   1228\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1229\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/neuefische/groupwork2/.venv/lib/python3.9/site-packages/pandas/io/common.py:667\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    664\u001b[0m     codecs\u001b[39m.\u001b[39mlookup_error(errors)\n\u001b[1;32m    666\u001b[0m \u001b[39m# open URLs\u001b[39;00m\n\u001b[0;32m--> 667\u001b[0m ioargs \u001b[39m=\u001b[39m _get_filepath_or_buffer(\n\u001b[1;32m    668\u001b[0m     path_or_buf,\n\u001b[1;32m    669\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[1;32m    670\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[1;32m    671\u001b[0m     mode\u001b[39m=\u001b[39;49mmode,\n\u001b[1;32m    672\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m    673\u001b[0m )\n\u001b[1;32m    675\u001b[0m handle \u001b[39m=\u001b[39m ioargs\u001b[39m.\u001b[39mfilepath_or_buffer\n\u001b[1;32m    676\u001b[0m handles: \u001b[39mlist\u001b[39m[BaseBuffer]\n",
      "File \u001b[0;32m~/neuefische/groupwork2/.venv/lib/python3.9/site-packages/pandas/io/common.py:336\u001b[0m, in \u001b[0;36m_get_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[39m# assuming storage_options is to be interpreted as headers\u001b[39;00m\n\u001b[1;32m    335\u001b[0m req_info \u001b[39m=\u001b[39m urllib\u001b[39m.\u001b[39mrequest\u001b[39m.\u001b[39mRequest(filepath_or_buffer, headers\u001b[39m=\u001b[39mstorage_options)\n\u001b[0;32m--> 336\u001b[0m \u001b[39mwith\u001b[39;00m urlopen(req_info) \u001b[39mas\u001b[39;00m req:\n\u001b[1;32m    337\u001b[0m     content_encoding \u001b[39m=\u001b[39m req\u001b[39m.\u001b[39mheaders\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mContent-Encoding\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    338\u001b[0m     \u001b[39mif\u001b[39;00m content_encoding \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mgzip\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    339\u001b[0m         \u001b[39m# Override compression based on Content-Encoding header\u001b[39;00m\n",
      "File \u001b[0;32m~/neuefische/groupwork2/.venv/lib/python3.9/site-packages/pandas/io/common.py:236\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[39mLazy-import wrapper for stdlib urlopen, as that imports a big chunk of\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[39mthe stdlib.\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    234\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39murllib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mrequest\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m \u001b[39mreturn\u001b[39;00m urllib\u001b[39m.\u001b[39;49mrequest\u001b[39m.\u001b[39;49murlopen(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.8/lib/python3.9/urllib/request.py:214\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    213\u001b[0m     opener \u001b[39m=\u001b[39m _opener\n\u001b[0;32m--> 214\u001b[0m \u001b[39mreturn\u001b[39;00m opener\u001b[39m.\u001b[39;49mopen(url, data, timeout)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.8/lib/python3.9/urllib/request.py:517\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    514\u001b[0m     req \u001b[39m=\u001b[39m meth(req)\n\u001b[1;32m    516\u001b[0m sys\u001b[39m.\u001b[39maudit(\u001b[39m'\u001b[39m\u001b[39murllib.Request\u001b[39m\u001b[39m'\u001b[39m, req\u001b[39m.\u001b[39mfull_url, req\u001b[39m.\u001b[39mdata, req\u001b[39m.\u001b[39mheaders, req\u001b[39m.\u001b[39mget_method())\n\u001b[0;32m--> 517\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_open(req, data)\n\u001b[1;32m    519\u001b[0m \u001b[39m# post-process response\u001b[39;00m\n\u001b[1;32m    520\u001b[0m meth_name \u001b[39m=\u001b[39m protocol\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m_response\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.8/lib/python3.9/urllib/request.py:534\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    531\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[1;32m    533\u001b[0m protocol \u001b[39m=\u001b[39m req\u001b[39m.\u001b[39mtype\n\u001b[0;32m--> 534\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_chain(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle_open, protocol, protocol \u001b[39m+\u001b[39;49m\n\u001b[1;32m    535\u001b[0m                           \u001b[39m'\u001b[39;49m\u001b[39m_open\u001b[39;49m\u001b[39m'\u001b[39;49m, req)\n\u001b[1;32m    536\u001b[0m \u001b[39mif\u001b[39;00m result:\n\u001b[1;32m    537\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.8/lib/python3.9/urllib/request.py:494\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[39mfor\u001b[39;00m handler \u001b[39min\u001b[39;00m handlers:\n\u001b[1;32m    493\u001b[0m     func \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 494\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    495\u001b[0m     \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    496\u001b[0m         \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.8/lib/python3.9/urllib/request.py:1389\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1388\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhttps_open\u001b[39m(\u001b[39mself\u001b[39m, req):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdo_open(http\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mHTTPSConnection, req,\n\u001b[1;32m   1390\u001b[0m         context\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_context, check_hostname\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_hostname)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.8/lib/python3.9/urllib/request.py:1346\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1344\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1345\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1346\u001b[0m         h\u001b[39m.\u001b[39;49mrequest(req\u001b[39m.\u001b[39;49mget_method(), req\u001b[39m.\u001b[39;49mselector, req\u001b[39m.\u001b[39;49mdata, headers,\n\u001b[1;32m   1347\u001b[0m                   encode_chunked\u001b[39m=\u001b[39;49mreq\u001b[39m.\u001b[39;49mhas_header(\u001b[39m'\u001b[39;49m\u001b[39mTransfer-encoding\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[1;32m   1348\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m err: \u001b[39m# timeout error\u001b[39;00m\n\u001b[1;32m   1349\u001b[0m         \u001b[39mraise\u001b[39;00m URLError(err)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.8/lib/python3.9/http/client.py:1285\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\u001b[39mself\u001b[39m, method, url, body\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, headers\u001b[39m=\u001b[39m{}, \u001b[39m*\u001b[39m,\n\u001b[1;32m   1283\u001b[0m             encode_chunked\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m   1284\u001b[0m     \u001b[39m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1285\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_request(method, url, body, headers, encode_chunked)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.8/lib/python3.9/http/client.py:1296\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1293\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39maccept-encoding\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m header_names:\n\u001b[1;32m   1294\u001b[0m     skips[\u001b[39m'\u001b[39m\u001b[39mskip_accept_encoding\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m-> 1296\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mputrequest(method, url, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mskips)\n\u001b[1;32m   1298\u001b[0m \u001b[39m# chunked encoding will happen if HTTP/1.1 is used and either\u001b[39;00m\n\u001b[1;32m   1299\u001b[0m \u001b[39m# the caller passes encode_chunked=True or the following\u001b[39;00m\n\u001b[1;32m   1300\u001b[0m \u001b[39m# conditions hold:\u001b[39;00m\n\u001b[1;32m   1301\u001b[0m \u001b[39m# 1. content-length has not been explicitly set\u001b[39;00m\n\u001b[1;32m   1302\u001b[0m \u001b[39m# 2. the body is a file or iterable, but not a str or bytes-like\u001b[39;00m\n\u001b[1;32m   1303\u001b[0m \u001b[39m# 3. Transfer-Encoding has NOT been explicitly set by the caller\u001b[39;00m\n\u001b[1;32m   1305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mcontent-length\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m header_names:\n\u001b[1;32m   1306\u001b[0m     \u001b[39m# only chunk body if not explicitly set for backwards\u001b[39;00m\n\u001b[1;32m   1307\u001b[0m     \u001b[39m# compatibility, assuming the client code is already handling the\u001b[39;00m\n\u001b[1;32m   1308\u001b[0m     \u001b[39m# chunking\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.8/lib/python3.9/http/client.py:1130\u001b[0m, in \u001b[0;36mHTTPConnection.putrequest\u001b[0;34m(self, method, url, skip_host, skip_accept_encoding)\u001b[0m\n\u001b[1;32m   1127\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_method \u001b[39m=\u001b[39m method\n\u001b[1;32m   1129\u001b[0m url \u001b[39m=\u001b[39m url \u001b[39mor\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m-> 1130\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_path(url)\n\u001b[1;32m   1132\u001b[0m request \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m (method, url, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_http_vsn_str)\n\u001b[1;32m   1134\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_encode_request(request))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.8/lib/python3.9/http/client.py:1230\u001b[0m, in \u001b[0;36mHTTPConnection._validate_path\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m   1228\u001b[0m match \u001b[39m=\u001b[39m _contains_disallowed_url_pchar_re\u001b[39m.\u001b[39msearch(url)\n\u001b[1;32m   1229\u001b[0m \u001b[39mif\u001b[39;00m match:\n\u001b[0;32m-> 1230\u001b[0m     \u001b[39mraise\u001b[39;00m InvalidURL(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mURL can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt contain control characters. \u001b[39m\u001b[39m{\u001b[39;00murl\u001b[39m!r}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1231\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(found at least \u001b[39m\u001b[39m{\u001b[39;00mmatch\u001b[39m.\u001b[39mgroup()\u001b[39m!r}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mInvalidURL\u001b[0m: URL can't contain control characters. \"/v2/daily/(<meteostat.interface.point.Point object at 0x15c6bbeb0>, Timestamp('2018-01-01 00:00:00'), Timestamp('2018-12-31 00:00:00')).csv.gz\" (found at least ' ')"
     ]
    }
   ],
   "source": [
    "# Reading Weather API Data \n",
    "\n",
    "dep_weather_df = df[['Dep_coor', 'DATOP', 'ID']]\n",
    "records = dep_weather_df.to_records(index=False)\n",
    "err_arr = []\n",
    "weather_dict = {}\n",
    "for i, record in enumerate(records):\n",
    "    if i < 5:\n",
    "\n",
    "        coor = Point(record[0][0],record[0][1])    \n",
    "        start = datetime(2018, 1, 1)\n",
    "        end = datetime(2018, 12, 31)\n",
    "        data = Daily((coor, start, end))\n",
    "        data = data.fetch()\n",
    "        port_dict[record[0]] = data\n",
    "\n",
    "\n",
    "print(err_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set time period\n",
    "\n",
    "weather_dict = {}\n",
    "start = datetime(2018, 1, 1)\n",
    "end = datetime(2018, 12, 31)\n",
    "\n",
    "# Create Point for Vancouver, BC\n",
    "vancouver = Point(49.2497, -123.1193, 70)\n",
    "\n",
    "# Get daily data for 2018\n",
    "data = Daily(vancouver, start, start)\n",
    "data = data.fetch()\n",
    "weather_dict[\"record\"] = data\n",
    "\n",
    "start_weather = (weather_dict.get('record'))\n",
    "\n",
    "df.rename('col_{}'.format, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>DATOP</th>\n",
       "      <th>FLTID</th>\n",
       "      <th>DEPSTN</th>\n",
       "      <th>ARRSTN</th>\n",
       "      <th>STD</th>\n",
       "      <th>STA</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>AC</th>\n",
       "      <th>target</th>\n",
       "      <th>Dep_coor</th>\n",
       "      <th>Arr_coor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_id_0</td>\n",
       "      <td>2016-01-03</td>\n",
       "      <td>TU 0712</td>\n",
       "      <td>CMN</td>\n",
       "      <td>TUN</td>\n",
       "      <td>2016-01-03 10:30:00</td>\n",
       "      <td>2016-01-03 12.55.00</td>\n",
       "      <td>ATA</td>\n",
       "      <td>TU 32AIMN</td>\n",
       "      <td>260.0</td>\n",
       "      <td>(33.3675003052, -7.5899701118)</td>\n",
       "      <td>(36.8510017395, 10.2271995544)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_id_1</td>\n",
       "      <td>2016-01-13</td>\n",
       "      <td>TU 0757</td>\n",
       "      <td>MXP</td>\n",
       "      <td>TUN</td>\n",
       "      <td>2016-01-13 15:05:00</td>\n",
       "      <td>2016-01-13 16.55.00</td>\n",
       "      <td>ATA</td>\n",
       "      <td>TU 31BIMO</td>\n",
       "      <td>20.0</td>\n",
       "      <td>(45.6305999756, 8.7281103134)</td>\n",
       "      <td>(36.8510017395, 10.2271995544)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_id_2</td>\n",
       "      <td>2016-01-16</td>\n",
       "      <td>TU 0214</td>\n",
       "      <td>TUN</td>\n",
       "      <td>IST</td>\n",
       "      <td>2016-01-16 04:10:00</td>\n",
       "      <td>2016-01-16 06.45.00</td>\n",
       "      <td>ATA</td>\n",
       "      <td>TU 32AIMN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(36.8510017395, 10.2271995544)</td>\n",
       "      <td>(41.275333, 28.752)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_id_3</td>\n",
       "      <td>2016-01-17</td>\n",
       "      <td>TU 0480</td>\n",
       "      <td>DJE</td>\n",
       "      <td>NTE</td>\n",
       "      <td>2016-01-17 14:10:00</td>\n",
       "      <td>2016-01-17 17.00.00</td>\n",
       "      <td>ATA</td>\n",
       "      <td>TU 736IOK</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(33.875, 10.7755002975)</td>\n",
       "      <td>(47.1531982422, -1.610730052)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_id_4</td>\n",
       "      <td>2016-01-17</td>\n",
       "      <td>TU 0338</td>\n",
       "      <td>TUN</td>\n",
       "      <td>ALG</td>\n",
       "      <td>2016-01-17 14:30:00</td>\n",
       "      <td>2016-01-17 15.50.00</td>\n",
       "      <td>ATA</td>\n",
       "      <td>TU 320IMU</td>\n",
       "      <td>22.0</td>\n",
       "      <td>(36.8510017395, 10.2271995544)</td>\n",
       "      <td>(36.6910018921, 3.2154099941)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID       DATOP     FLTID DEPSTN ARRSTN                  STD  \\\n",
       "0  train_id_0  2016-01-03  TU 0712     CMN    TUN  2016-01-03 10:30:00   \n",
       "1  train_id_1  2016-01-13  TU 0757     MXP    TUN  2016-01-13 15:05:00   \n",
       "2  train_id_2  2016-01-16  TU 0214     TUN    IST  2016-01-16 04:10:00   \n",
       "3  train_id_3  2016-01-17  TU 0480     DJE    NTE  2016-01-17 14:10:00   \n",
       "4  train_id_4  2016-01-17  TU 0338     TUN    ALG  2016-01-17 14:30:00   \n",
       "\n",
       "                   STA STATUS         AC  target  \\\n",
       "0  2016-01-03 12.55.00    ATA  TU 32AIMN   260.0   \n",
       "1  2016-01-13 16.55.00    ATA  TU 31BIMO    20.0   \n",
       "2  2016-01-16 06.45.00    ATA  TU 32AIMN     0.0   \n",
       "3  2016-01-17 17.00.00    ATA  TU 736IOK     0.0   \n",
       "4  2016-01-17 15.50.00    ATA  TU 320IMU    22.0   \n",
       "\n",
       "                         Dep_coor                        Arr_coor  \n",
       "0  (33.3675003052, -7.5899701118)  (36.8510017395, 10.2271995544)  \n",
       "1   (45.6305999756, 8.7281103134)  (36.8510017395, 10.2271995544)  \n",
       "2  (36.8510017395, 10.2271995544)             (41.275333, 28.752)  \n",
       "3         (33.875, 10.7755002975)   (47.1531982422, -1.610730052)  \n",
       "4  (36.8510017395, 10.2271995544)   (36.6910018921, 3.2154099941)  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DEPSTN</th>\n",
       "      <th>ARRSTN</th>\n",
       "      <th>STD</th>\n",
       "      <th>STA</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CMN</td>\n",
       "      <td>TUN</td>\n",
       "      <td>2016-01-03 10:30:00</td>\n",
       "      <td>2016-01-03 12.55.00</td>\n",
       "      <td>260.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MXP</td>\n",
       "      <td>TUN</td>\n",
       "      <td>2016-01-13 15:05:00</td>\n",
       "      <td>2016-01-13 16.55.00</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TUN</td>\n",
       "      <td>IST</td>\n",
       "      <td>2016-01-16 04:10:00</td>\n",
       "      <td>2016-01-16 06.45.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DJE</td>\n",
       "      <td>NTE</td>\n",
       "      <td>2016-01-17 14:10:00</td>\n",
       "      <td>2016-01-17 17.00.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TUN</td>\n",
       "      <td>ALG</td>\n",
       "      <td>2016-01-17 14:30:00</td>\n",
       "      <td>2016-01-17 15.50.00</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  DEPSTN ARRSTN                  STD                  STA  target\n",
       "0    CMN    TUN  2016-01-03 10:30:00  2016-01-03 12.55.00   260.0\n",
       "1    MXP    TUN  2016-01-13 15:05:00  2016-01-13 16.55.00    20.0\n",
       "2    TUN    IST  2016-01-16 04:10:00  2016-01-16 06.45.00     0.0\n",
       "3    DJE    NTE  2016-01-17 14:10:00  2016-01-17 17.00.00     0.0\n",
       "4    TUN    ALG  2016-01-17 14:30:00  2016-01-17 15.50.00    22.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# droping rows:\n",
    "\n",
    "drop_arr = ['ID', 'DATOP', 'AC', 'FLTID', 'STATUS']\n",
    "\n",
    "try:\n",
    "    df = df.drop(labels=drop_arr, axis=1)\n",
    "except KeyError:\n",
    "    pass\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Converting timestamps to Datetime obj.\"\"\"\n",
    "\n",
    "df['STA'] = df['STA'].str.replace('.', ':', regex=False)\n",
    "df['STA'] = pd.to_datetime(df['STA']).map(pd.Timestamp.timestamp)\n",
    "\n",
    "df['STD'] = pd.to_datetime(df['STD']).map(pd.Timestamp.timestamp)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" create Target\"\"\"\n",
    "\n",
    "X = df.drop('target', axis=1)\n",
    "y= df['target']\n",
    "\n",
    "\"\"\"Target info\"\"\"\n",
    "print(f\"We have {X.shape[0]} observations in our dataset and {X.shape[1]} features\")\n",
    "print(f\"Our target vector has also {y.shape[0]} values\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feats = ['DEPSTN', 'ARRSTN']\n",
    "\n",
    "X = pd.get_dummies(X, columns=cat_feats, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" train/test split\"\"\"\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RSEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Very simple Baseline model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_reg = DecisionTreeRegressor(max_depth=4)\n",
    "dec_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_dec_tree_predicted = dec_reg.predict(X_test)\n",
    "y_test_lin_predicted = lin_reg.predict(X_test)\n",
    "\n",
    "print('Decision Tree')\n",
    "print('_'*20)\n",
    "print(\"Mean Squared Error: {:.2f}\".format(mean_squared_error(y_test, y_test_dec_tree_predicted)))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print('Linear Regression')\n",
    "print('_'*20)\n",
    "print(\"Mean Squared Error: {:.2f}\".format(mean_squared_error(y_test, y_test_lin_predicted)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nice to have:\n",
    "\n",
    "Plots: \n",
    "\n",
    "- Airport with most delay \n",
    "\n",
    "- cluster time of year (delay)\n",
    "\n",
    "- find routes that are late most "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "\n",
    "____\n",
    "This Project was Part of the Data Science Bootcamp at NeueFische, for more information visit: \n",
    "\n",
    "[NeueFische](https://www.neuefische.de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d68d3417c6c37cd8ebd0d320f737814f278e7fee5045e744da2157e627f0f7b0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
